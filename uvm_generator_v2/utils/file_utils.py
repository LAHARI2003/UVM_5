"""
File management utilities for UVM Generator - V2 (Improved)

Key Improvements:
- Better encoding handling
- More flexible example file collection
- Improved summary generation
- Support for different project structures
"""

import os
import re
import shutil
import logging
from pathlib import Path
from typing import List, Dict, Optional, Set
from datetime import datetime

logger = logging.getLogger(__name__)


class FileManager:
    """Manages file operations for generated UVM files"""
    
    def __init__(self, output_base: str):
        self.output_base = Path(output_base)
        self.created_files: List[Path] = []
        self.skipped_files: List[Path] = []
    
    def setup_directories(self, custom_dirs: List[str] = None):
        """Create output directory structure"""
        default_dirs = [
            "ip_infra/env",
            "ip_infra/interface",
            "ip_infra/virtual_sequencer",
            "ip_infra/pkg",
            "ip_infra/tb",
            "ip_infra/scoreboard",
            "tests/tests",
            "tests/virtual_sequences",
        ]
        
        dirs = custom_dirs if custom_dirs else default_dirs
        
        created = []
        for d in dirs:
            dir_path = self.output_base / d
            dir_path.mkdir(parents=True, exist_ok=True)
            created.append(dir_path)
        
        return created
    
    def write_file(
        self, 
        relative_path: str, 
        content: str, 
        add_header: bool = True,
        skip_if_exists: bool = False
    ) -> Path:
        """
        Write content to file with optional auto-generated header
        
        Args:
            relative_path: Path relative to output_base
            content: File content
            add_header: Whether to add auto-generated header
            skip_if_exists: Skip writing if file already exists
            
        Returns:
            Path to the written file
        """
        file_path = self.output_base / relative_path
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        if skip_if_exists and file_path.exists():
            logger.info(f"Skipping existing file: {file_path}")
            self.skipped_files.append(file_path)
            return file_path
        
        if add_header:
            header = self._generate_header(file_path.name)
            content = header + content
        
        # Use UTF-8 encoding for cross-platform compatibility
        try:
            file_path.write_text(content, encoding='utf-8')
        except UnicodeEncodeError:
            # Fallback: remove non-ASCII characters
            content_clean = content.encode('ascii', 'ignore').decode('ascii')
            file_path.write_text(content_clean, encoding='utf-8')
            logger.warning(f"Removed non-ASCII characters from {file_path.name}")
        
        self.created_files.append(file_path)
        return file_path
    
    def _generate_header(self, filename: str) -> str:
        """Generate auto-generated file header"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return f"""//==============================================================================
// File: {filename}
// Auto-generated by UVM Generator V2
// Generated: {timestamp}
// 
// WARNING: This file is auto-generated. Manual changes may be overwritten.
//==============================================================================

"""
    
    def copy_file(self, source: str, dest_relative: str) -> Path:
        """Copy a file to the output directory"""
        dest_path = self.output_base / dest_relative
        dest_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(source, dest_path)
        self.created_files.append(dest_path)
        return dest_path
    
    def read_file_safe(self, file_path: str, encodings: List[str] = None) -> str:
        """Read a file with multiple encoding attempts"""
        encodings = encodings or ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']
        path = Path(file_path)
        
        if not path.exists():
            return ""
        
        for encoding in encodings:
            try:
                return path.read_text(encoding=encoding)
            except (UnicodeDecodeError, UnicodeError):
                continue
        
        logger.warning(f"Could not decode file {file_path} with any encoding")
        return ""
    
    def get_created_files(self) -> List[Path]:
        """Return list of all created files"""
        return self.created_files
    
    def generate_summary(self) -> str:
        """Generate summary of created files"""
        lines = ["=" * 60]
        lines.append("Generated Files Summary")
        lines.append("=" * 60)
        
        # Group by directory
        by_dir: Dict[str, List[str]] = {}
        for f in self.created_files:
            try:
                dir_name = str(f.parent.relative_to(self.output_base))
            except ValueError:
                dir_name = str(f.parent)
            if dir_name not in by_dir:
                by_dir[dir_name] = []
            by_dir[dir_name].append(f.name)
        
        for dir_name, files in sorted(by_dir.items()):
            lines.append(f"\n{dir_name}/")
            for f in sorted(files):
                lines.append(f"  - {f}")
        
        lines.append(f"\nTotal files generated: {len(self.created_files)}")
        if self.skipped_files:
            lines.append(f"Files skipped (already exist): {len(self.skipped_files)}")
        lines.append("=" * 60)
        
        return "\n".join(lines)


def collect_uvc_info(uvc_lib_path: str) -> Dict[str, str]:
    """
    Collect information about available UVCs
    
    Searches for UVC sequence files and extracts class declarations
    """
    uvc_info = {}
    uvc_path = Path(uvc_lib_path)
    
    if not uvc_path.exists():
        logger.warning(f"UVC library path not found: {uvc_lib_path}")
        return uvc_info
    
    # Search patterns for sequence files
    search_patterns = [
        "*/sequences/*.sv",
        "*/sv/*.sv",
        "*/*.sv",
        "**/*_sequence*.sv",
        "**/*_seq.sv"
    ]
    
    found_files: Set[Path] = set()
    for pattern in search_patterns:
        found_files.update(uvc_path.glob(pattern))
    
    for seq_file in found_files:
        try:
            content = seq_file.read_text(encoding='utf-8')
        except UnicodeDecodeError:
            try:
                content = seq_file.read_text(encoding='latin-1')
            except Exception:
                continue
        
        # Extract class declarations
        matches = re.findall(r'class\s+(\w+).*?extends\s+(\w+)', content, re.DOTALL)
        if matches:
            uvc_name = seq_file.parent.parent.name if seq_file.parent.name in ['sequences', 'sv'] else seq_file.parent.name
            if uvc_name not in uvc_info:
                uvc_info[uvc_name] = ""
            for class_name, base_class in matches[:5]:  # Limit to first 5 classes
                uvc_info[uvc_name] += f"class {class_name} extends {base_class};\n"
    
    return uvc_info


def collect_example_files(example_dir: str, custom_patterns: Dict[str, List[str]] = None) -> Dict[str, str]:
    """
    Collect example files for few-shot learning
    
    Args:
        example_dir: Directory containing example files
        custom_patterns: Override default patterns for finding examples
        
    Returns:
        Dict mapping example type to file content
    """
    examples = {}
    example_path = Path(example_dir)
    
    if not example_path.exists():
        logger.warning(f"Example directory not found: {example_dir}")
        return examples
    
    # Default patterns (can be overridden)
    patterns = custom_patterns or {
        'env': ['*env*.sv', '*_env.sv', '**/*_env.sv'],
        'vseqr': ['*virtual_sequencer*.sv', '*vseqr*.sv', '**/*virtual_sequencer*.sv'],
        'interface': ['*interface*.sv', '*_if*.sv', '*_if.sv', '**/*_if.sv'],
        'package': ['*package*.sv', '*_pkg*.sv', '**/*_pkg.sv'],
        'test': ['*_test.sv', '**/*_test.sv'],
        'vseq': ['*_vseq.sv', '**/*_vseq.sv'],
        'scoreboard': ['*scoreboard*.sv', '*_sb.sv', '**/*scoreboard*.sv'],
        'tb': ['*_tb.sv', '*_top.sv', '**/*_tb.sv'],
    }
    
    for key, pats in patterns.items():
        for pat in pats:
            for f in example_path.rglob(pat.lstrip('**/')) if '**' in pat else [example_path / pat]:
                if hasattr(f, 'is_file') and f.is_file():
                    try:
                        content = f.read_text(encoding='utf-8')
                        examples[key] = content
                        logger.debug(f"Found example for '{key}': {f}")
                        break
                    except (UnicodeDecodeError, FileNotFoundError):
                        continue
            # Also try glob for wildcards
            if key not in examples:
                for f in example_path.glob(pat):
                    if f.is_file():
                        try:
                            content = f.read_text(encoding='utf-8')
                            examples[key] = content
                            logger.debug(f"Found example for '{key}': {f}")
                            break
                        except (UnicodeDecodeError, FileNotFoundError):
                            continue
            if key in examples:
                break
    
    # Log what was found
    found_keys = list(examples.keys())
    missing_keys = [k for k in patterns.keys() if k not in examples]
    if found_keys:
        logger.info(f"Found examples for: {', '.join(found_keys)}")
    if missing_keys:
        logger.warning(f"No examples found for: {', '.join(missing_keys)}")
    
    return examples


def derive_names_from_block(block_name: str, naming_config: Dict = None) -> Dict[str, str]:
    """
    Derive all naming conventions from block name
    
    Args:
        block_name: The DUT/block name from Block YAML
        naming_config: Optional naming configuration overrides
        
    Returns:
        Dict with derived names
    """
    # Clean the block name
    clean_name = block_name.strip()
    
    # Remove common suffixes
    for suffix in ['_m', '_top', '_wrapper', '_wrap', '_dut']:
        if clean_name.endswith(suffix):
            clean_name = clean_name[:-len(suffix)]
    
    # Create variations
    base_name = clean_name
    snake_name = re.sub(r'([A-Z])', r'_\1', base_name).lower().strip('_')
    snake_name = re.sub(r'_+', '_', snake_name)  # Remove double underscores
    
    # Default naming conventions
    names = {
        'block_name': block_name,
        'clean_name': clean_name,
        'snake_name': snake_name,
        'env_class': f"{snake_name}_env",
        'vseqr_class': f"{snake_name}_virtual_sequencer",
        'interface_name': f"{snake_name}_if",
        'package_name': f"{snake_name}_pkg",
        'scoreboard_class': f"{snake_name}_scoreboard",
        'tb_module': f"{snake_name}_tb_top",
    }
    
    # Apply any naming config overrides
    if naming_config:
        prefix = naming_config.get('prefix', '')
        suffix = naming_config.get('suffix', '')
        
        if prefix:
            names['env_class'] = f"{prefix}_{names['env_class']}"
            names['vseqr_class'] = f"{prefix}_{names['vseqr_class']}"
            names['scoreboard_class'] = f"{prefix}_{names['scoreboard_class']}"
        
        # Direct overrides
        for key in ['env_class', 'vseqr_class', 'interface_name', 'package_name', 'scoreboard_class']:
            if key in naming_config:
                names[key] = naming_config[key]
    
    return names
